{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77d98a4e-9418-4397-8b7a-8088621543bc",
   "metadata": {},
   "source": [
    "# Lista 2\n",
    "\n",
    "## Uczenie maszynowe i sztuczna inteligencja\n",
    "\n",
    "* [Naiwny klasyfikator bayesowski](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) oraz [Naiwny wielomianowy klasyfikator bayesowski](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Multinomial_naive_Bayes)\n",
    "* [Tokenizacja](https://en.wikipedia.org/wiki/Lexical_analysis#Tokenization)\n",
    "* [Multizbiór słów](https://en.wikipedia.org/wiki/Bag-of-words_model)\n",
    "* [N-gram](https://en.wikipedia.org/wiki/N-gram), [Bigram](https://en.wikipedia.org/wiki/Bigram), [Trigram](https://en.wikipedia.org/wiki/Trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fd6799-47e0-46c6-b8e3-64a0cb60587c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Wprowadzenie \n",
    "\n",
    "Spamowanie jest jednym z najprostszych ataków w przesyłaniu wiadomości e-mail. Użytkownicy często otrzymują irytujące wiadomości spamowe oraz złośliwe wiadomości phishingowe, subskrybując różne strony internetowe, produkty, usługi, katalogi, biuletyny informacyjne oraz inne rodzaje komunikacji elektronicznej. W niektórych przypadkach, spamowe wiadomości e-mail są generowane przez wirusy lub konie trojańskie rozsyłane masowo.\n",
    "\n",
    "Istnieje wiele rozwiązań do filtrowania spamu, takich jak techniki filtrowania na czarnej i białej liście, podejścia oparte na drzewach decyzyjnych, podejścia oparte na adresach e-mail oraz metody oparte na uczeniu maszynowym. Większość z nich opiera się głównie na analizie tekstu zawartości e-maila. W rezultacie rośnie zapotrzebowanie na skuteczne filtry antyspamowe, które automatycznie identyfikują i usuwają wiadomości spamowe lub ostrzegają użytkowników przed możliwymi wiadomościami spamowymi. Jednak spamerzy zawsze badają luki istniejących technik filtrowania spamu i wprowadzają nowy projekt do rozprzestrzeniania spamu w szerokim zakresie np. atak tokenizacji czasami wprowadza w błąd filtry antyspamowe, dodając dodatkowe spacje. Dlatego też treści e-maili muszą być strukturalizowane. Ponadto, pomimo posiadania najwyższej dokładności w wykrywaniu spamu za pomocą uczenia maszynowego, fałszywe pozytywy (False Positive, FP) stanowią problem z powodu jednorazowego wykrywania zagrożeń e-mailowych. Aby zaradzić problemom z fałszywymi pozytywami oraz zmianom w różnych projektach ataków, z tekstu usuwane są słowa kluczowe oraz inne niepożądane informacje przed dalszą analizą. Po wstępnym przetwarzaniu, te teksty przechodzą przez liczne metody ekstrakcji cech, takie jak word2vec, word n-gram, character n-gram oraz kombinacje n-gramów o zmiennych długościach. Różne techniki uczenia maszynowego, takie jak support vector machine (SVM), decision tree (DT), logistic regression (LR) oraz multinomial naıve bayes (MNB), są stosowany aby dokonać klasyfikacji e-maili.\n",
    "\n",
    "Na tej liste skoncentrujemy się tylko na metodzie naiwnego klasyfikatora bayesowskiego przedstawionego na wykładzie wraz z wersją [wielomianową](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Multinomial_naive_Bayes).\n",
    "\n",
    "#### **Uwaga**\n",
    "\n",
    "**Wszystkie implementacje klasyfikatorów należy napisać samemu. Na tej liście nie korzystamy z implementacji klasyfikatorów istniejących w popularnych bibliotekach.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2ecc4f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a550496e-1cac-4071-935a-6f92eec8afd7",
   "metadata": {},
   "source": [
    "\n",
    "# Klasyfikatory Naiwnego Bayesa (NB)\n",
    "\n",
    "W naszych eksperymentach po wstępnym przetworzeniu każda wiadomość jest ostatecznie reprezentowana jako wektor $\\mathbf{x}=(x_1, \\ldots , x_m)$, gdzie $x_1, \\ldots , x_m$ są wartościami atrybutów $X_1, \\ldots , X_m$ , a każdy atrybut dostarcza informacje o określonym tokenie wiadomości. W najprostszym przypadku wszystkie atrybuty są wartościami boolowskimi: $X_i = 1$, jeśli wiadomość zawiera dany token; w przeciwnym razie, $X_i = 0$. Alternatywnie, ich wartości mogą być częstotliwościami tokenów (TF), pokazującymi, ile razy odpowiadający token występuje w wiadomości. Atrybuty z wartościami TF przenoszą więcej informacji niż atrybuty boolowskie.\n",
    "\n",
    "Z twierdzenia Bayesa wynika, że prawdopodobieństwo, że wiadomość o wektorze $\\mathbf{x} = (x_1, \\ldots, x_m)$ należy do kategorii $c$, wynosi: \n",
    "\n",
    "$$\n",
    "p(c | \\mathbf{x}) = \\frac{p(c) \\cdot p(\\mathbf{x} | c)}{p(\\mathbf{x})}\n",
    "$$\n",
    "\n",
    "Ponieważ mianownik nie zależy od kategorii, klasyfikator NB klasyfikuje każdą wiadomość do kategorii, która maksymalizuje $p(c) \\cdot p(\\mathbf{x} | c)$. W przypadku filtrowania spamu oznacza to klasyfikowanie wiadomości jako spamu, gdy: \n",
    "\n",
    "$$\n",
    "\\frac{p(c_s) \\cdot p(\\mathbf{x} | c_s)}{p(c_s) \\cdot p(\\mathbf{x} | c_s) + p(c_h) \\cdot p(\\mathbf{x} | c_h)} > T\n",
    "$$\n",
    "\n",
    "gdzie $T = 0.5$, a $c_h$ i $c_s$ oznaczają kategorie ham i spam. Zmieniając $T$, można zdecydować się na więcej prawdziwych negatywów (poprawnie sklasyfikowane wiadomości ham) kosztem mniej prawdziwych pozytywów (poprawnie sklasyfikowane wiadomości spam), lub odwrotnie. Prawdopodobieństwa a priori $p(c)$ są zwykle szacowane przez podzielenie liczby treningowych wiadomości kategorii $c$ przez łączną liczbę treningowych wiadomości. Prawdopodobieństwa $p(\\mathbf{x} | c)$ są szacowane w różny sposób w każdej wersji NB - patrz wykład.\n",
    "\n",
    "# Naiwny klasyfikator bayesowski wielomianowy (MNB)\n",
    "\n",
    "Klasyfikator [wielomianowy](https://en.wikipedia.org/wiki/Multinomial_distribution) bayesowski z atrybutami TF traktuje każdą wiadomość $d$ jako [multizbiór]((https://en.wikipedia.org/wiki/Bag-of-words_model)) tokenów, zawierający każdy token $t_i$ tyle razy, ile występuje w $d$. Dlatego $d$ można przedstawić jako $\\mathbf{x} = (x_1, ..., x_m)$, gdzie każde $x_i$ to teraz liczba wystąpień $t_i$ w $d$. Ponadto, każda wiadomość $d$ z kategorii $c$ jest postrzegana jako wynik niezależnego wyboru $|d|$ tokenów z $F=\\{t_1,\\ldots,t_m\\}$ z powtórzeniami, z prawdopodobieństwem $p(t_i | c)$ dla każdego $t_i$. Wówczas $p(\\mathbf{x} | c)$ jest rozkładem wielomianowym:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x} \\mid c) = p(|d|) \\cdot |d|! \\cdot \\prod_{i=1}^{d} \\frac{p(t_i \\mid c)^{x_i}}{x_i !}\n",
    "$$\n",
    "\n",
    "gdzie zakładamy, że $|d|$ nie zależy od kategorii $c$. Jest to dodatkowe uproszczające założenie, które jest bardziej dyskusyjne w filtrowaniu spamu. Na przykład, prawdopodobieństwo otrzymania bardzo długiej wiadomości spamowej wydaje się mniejsze niż prawdopodobieństwo otrzymania równie długiej wiadomości ham. Kryterium klasyfikacji wiadomości jako spamu staje się:\n",
    "\n",
    "$$\n",
    "\\frac{p(c_s) \\cdot \\prod_{i=1}^{m} p(t_i \\mid c_s)^{x_i}}{p(c_s)\\cdot\\prod_{i=1}^{m} p(t_i \\mid c_s)^{x_i} + p(c_h)\\cdot\\prod_{i=1}^{m} p(t_i \\mid c_h)^{x_i}}  > T\n",
    "$$\n",
    "\n",
    "gdzie każde $p(t_i | c)$ jest szacowane jako:\n",
    "\n",
    "$$\n",
    "p(t \\mid c) = \\frac{\\alpha + N_{t,c}}{\\alpha \\cdot m + N_c}\n",
    "$$\n",
    "gdzie $N_{t,c}$ to liczba wystąpień tokena $t$ w treningowych wiadomościach kategorii $c$, podczas gdy $N_c = \\sum_{i=1}^{m} N_{t_i,c}$ to łączna liczba wiadomości treningowych kategorii $c$. W praktyce dodaje się jeszcze parametr $\\alpha$ który reprezentuje wygładzenie (smoothing) i rozwiązuje problem zerowego prawdopodobieństwa, patrz [http://www.paulgraham.com/spam.html](http://www.paulgraham.com/spam.html) (np. $\\alpha=1$).\n",
    "\n",
    "\n",
    "### Przykładowe dane wielomianowe\n",
    "\n",
    "Zatem każda wiadomość $d$  składa się z różnych tokenów $t_i$, a każde z tych $t_i$ należy do słownika $\\mathcal{V}$. Jeśli $\\mathcal{V}$ zawiera np. $8$ tokenów, $t_1,t_2,...,t_8$, a wiadomość to: $t_1 t_2 t_2 t_6 t_3 t_2 t_8$, reprezentacja tej wiadomości będzie następująca:\n",
    "\n",
    "| |$t_1$|$t_2$|$t_3$|$t_4$|$t_5$|$t_6$|$t_7$|$t_8$|\n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "|$\\mathbf{x}$| 1|3 |1 | 0| 0|1 | 0|1 |\n",
    "\n",
    "Po dodaniu kilku innych losowych wiadomości, zbiór danych wygląda tak:\n",
    "\n",
    "|$t_1$|$t_2$|$t_3$|$t_4$|$t_5$|$t_6$|$t_7$|$t_8$|$c$|\n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "| 1|3 |1 | 0| 0|1 | 0|1 | spam|\n",
    "| 1|0 |0 | 0| 1|1 | 1|3 | ham|\n",
    "| 0|0 |0 | 0| 0|2 | 1|2 | spam|\n",
    "\n",
    "Przyjmując klasy ($1$-spam,$0$-ham) mamy $c = [1,0,1]$. Teraz, porównując z równaniem powyżej,\n",
    "\n",
    "- $N_{t_i,c}$ to liczba wystąpień cechy $t_i$ w każdej unikalnej klasie $c$. Na przykład, dla $c=1$, $N_{t_1,c}=1, N_{t_6,c}=3$\n",
    "- $N_c$ to całkowita liczba wystąpień wszystkich cech w każdej unikalnej klasie $c$. Na przykład, dla $c=1$, $N_c=12$\n",
    "- $m=8$ to całkowita liczba cech\n",
    "- $\\alpha=1$ jest znany jako parametr wygładzania. Jest on potrzebny do problemu zerowego prawdopodobieństwa (patrz [http://www.paulgraham.com/spam.html](http://www.paulgraham.com/spam.html))\n",
    "\n",
    "# Niedomiar zmiennoprzecinkowy (floating point underflow)\n",
    "\n",
    "Aby uniknąć problemu niedomiaru zmiennoprzecinkowego, mnożenie zbioru małych prawdopodobieństw, czyli po prostu iloczyn stanie się zbyt mały, aby go reprezentować i zostanie zastąpiony przez 0. Zamiast obliczać\n",
    "$$\n",
    "P(c) \\prod_{i=1}^m P(t_i | c)\n",
    "$$\n",
    "co może spowodować niedomiar, rozważmy obliczenie logarytmu tego wyrażenia,\n",
    "$$\n",
    "\\log\\left(P(c) \\prod_{i=1}^m P(t_i | c)\\right)\n",
    "$$\n",
    "co równoważnie można zapisać jako\n",
    "$$\n",
    "\\log(P(c))+ \\sum_{i=1}^m \\log(P(t_i | c))\n",
    "$$\n",
    "Następnie zauważ, że jeśli\n",
    "$$\n",
    "\\log(P(c_s))+ \\sum_{i=1}^m \\log(P(t_i | c_s)) > \\log(P(c_h))+ \\sum_{i=1}^m \\log(P(t_i | c_h))\n",
    "$$\n",
    "wtedy, ponieważ $\\log(x) > \\log(y)$ iff $x > y$, to\n",
    "$$\n",
    "P(c_s) \\prod_{i=1}^m P(t_i | c_s) > P(c_h) \\prod_{i=1}^m P(t_i | c_h)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "008940dd-f67c-425c-b322-4113da6837bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation\n",
    "\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "dataset_url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zipped_filename = \"sms_spam_collection.zip\"\n",
    "dataset_filename = \"SMSSpamCollection\"\n",
    "\n",
    "r = requests.get(dataset_url, allow_redirects=True)\n",
    "with open(zipped_filename, 'wb') as file:\n",
    "    file.write(r.content)\n",
    "\n",
    "with zipfile.ZipFile(zipped_filename, 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0adeba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import re\n",
    "\n",
    "HAM=0\n",
    "SPAM=1\n",
    "\n",
    "only_spam = []\n",
    "only_ham = []\n",
    "\n",
    "def preprocess_line(text_: str) -> str:\n",
    "    text_ = re.sub(r'\\W', ' ', text)\n",
    "    text_ = re.sub(r'\\s+', ' ', text, flags=re.I).lower()  \n",
    "    return text_\n",
    "\n",
    "with open(dataset_filename) as file:\n",
    "    for msg in file.readlines():\n",
    "        splitted = msg.split(\"\\t\")\n",
    "        kind = splitted[0]\n",
    "        text = splitted[1]\n",
    "        text = preprocess_line(text[:-1]) # remove newline in the end\n",
    "        if kind == 'ham':\n",
    "            only_ham.append(text)\n",
    "        else:\n",
    "            only_spam.append(text)   \n",
    "            \n",
    "all_content = only_spam + only_ham\n",
    "labels = [SPAM]*len(only_spam) + [HAM]*len(only_ham)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be6d73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split # type: ignore\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "163547a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(self) -> None:\n",
    "        self.threshold=0.99\n",
    "        self.classes = None\n",
    "        self.class_probs = None\n",
    "        self.token_counts_per_class = {}\n",
    "        self.total_tokens_per_class = {}\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.classes, class_counts = np.unique(y, return_counts=True)\n",
    "        self.class_probs = class_counts / len(y)\n",
    "\n",
    "        for cls in self.classes:\n",
    "            X_cls = X[np.where(y == cls)]\n",
    "            # sumujemy wystapienia we wszystkich wiadomosciach\n",
    "            self.token_counts_per_class[cls] = np.sum(X_cls, axis=0) + 0.01 # by pozniej wartosc dla 0 byla git\n",
    "            # sumujemy wszystkie tokeny w wiadomosciach\n",
    "            self.total_tokens_per_class[cls] = np.sum(self.token_counts_per_class[cls])\n",
    "    \n",
    "    def probability_of_x_condition_c(self, x, c) -> float: # type: ignore\n",
    "        pass\n",
    "        \n",
    "    def softmax(self, values):\n",
    "        max_val = np.max(values)\n",
    "        exp_vals = np.exp(values - max_val)\n",
    "        return exp_vals / np.sum(exp_vals)\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            probs = [\n",
    "                self.probability_of_x_condition_c(x, c)\n",
    "                for c in self.classes # type: ignore\n",
    "            ]\n",
    "            probs = self.softmax(probs)\n",
    "            predictions.append(SPAM if probs[SPAM] > self.threshold else HAM)\n",
    "        return predictions\n",
    "    \n",
    "def test(classifier: Classifier, \n",
    "         ngram_range: tuple[int, int], \n",
    "         X_train,\n",
    "         y_train,\n",
    "         X_test,\n",
    "         y_test\n",
    "):\n",
    "    vectorizer=CountVectorizer(ngram_range=ngram_range)\n",
    "    X_train_counts = vectorizer.fit_transform(X_train)\n",
    "    X_test_counts = vectorizer.transform(X_test)\n",
    "    \n",
    "    classifier.fit(X_train_counts.toarray(), y_train) # type: ignore\n",
    "    predictions = classifier.predict(X_test_counts.toarray()) # type: ignore\n",
    "    \n",
    "    Accuracy = round(accuracy_score(y_test, predictions), 4)\n",
    "    Precision = round(precision_score(y_test, predictions), 4) # type: ignore\n",
    "    Recall = round(recall_score(y_test, predictions), 4) # type: ignore\n",
    "    F1_Score = round(f1_score(y_test, predictions), 4) # type: ignore\n",
    "    \n",
    "    column_width=9\n",
    "    print(f\"\"\"Results for Classifier:{type(classifier).__name__}, {ngram_range=}\n",
    "{'Accuracy'.ljust(column_width, ' ')} | {'Precision'.ljust(column_width, ' ')} | {'Recall'.ljust(column_width, ' ')} | {'F1_Score'.ljust(column_width, ' ')}\n",
    "{str(Accuracy).ljust(column_width)} | {str(Precision).ljust(column_width)} | {str(Recall).ljust(column_width)} | {str(F1_Score).ljust(column_width)}\"\"\")\n",
    "    \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a538afe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_content, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ff1e5a-8599-412a-9494-45699a65a2fb",
   "metadata": {},
   "source": [
    "## Zadanie 1 (10pt)\n",
    "\n",
    "### Klasyfikator oparty na algorytmie NB\n",
    "\n",
    "#### Cel:\n",
    "Zbudować prosty klasyfikator spamu oparty na NB, który będzie w stanie wykryć i odfiltrować niechciane wiadomości e-mail.\n",
    "\n",
    "#### Opis:\n",
    "1. Zbierz zbiór danych zawierający etykiety (spam/nie-spam) oraz treść wiadomości e-mail np. [Enron-Spam](http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/index.html) lub [SMS Spam Collection](https://archive.ics.uci.edu/dataset/228/sms+spam+collection) lub [E-mail Spam](https://www.kaggle.com/datasets/balaka18/email-spam-classification-dataset-csv) lub ...\n",
    "2. Przygotuj dane poprzez tokenizację słów i usuń zbędne znaki interpunkcyjne.\n",
    "3. Zaimplementuj NB, który będzie w stanie klasyfikować wiadomości jako spam lub nie-spam na podstawie występujących słów.\n",
    "4. Podziel dane na zbiór treningowy i testowy (np. 70% do treningu, 30% do testu).\n",
    "5. Wytrenuj klasyfikator NB na danych treningowych.\n",
    "6. Przetestuj klasyfikator na danych testowych i oceniaj jego skuteczność przy użyciu metryk: [precision i recall](https://en.wikipedia.org/wiki/Precision_and_recall), [f1-score](https://en.wikipedia.org/wiki/F-score) oraz [accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision).\n",
    "7. Dokonaj analizy wyników i przedstaw wnioski.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3db03424-f98e-4b03-8cb3-cbb1cb5d4935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Classifier:NBClassifier, ngram_range=(1, 1)\n",
      "Accuracy  | Precision | Recall    | F1_Score \n",
      "0.9815    | 0.9957    | 0.8851    | 0.9371   \n"
     ]
    }
   ],
   "source": [
    "class NBClassifier(Classifier):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "    def probability_of_x_condition_c(self, x, c) -> float:\n",
    "        log_p = np.log(self.class_probs[c]) # type: ignore\n",
    "        for token in x.nonzero()[0]:\n",
    "            am_token = self.token_counts_per_class[c][token] \n",
    "            log_p += np.log(am_token) \n",
    "            log_p -= np.log(self.total_tokens_per_class[c])\n",
    "        return log_p\n",
    "\n",
    "test(NBClassifier(), (1,1), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a933bb-c803-4e52-a562-e2a47944fb5f",
   "metadata": {},
   "source": [
    "## Zadanie 2 (15pt)\n",
    "\n",
    "### Klasyfikator oparty na n-gramach MNB\n",
    "\n",
    "#### Cel:\n",
    "Zbudować klasyfikator spamu, wykorzystując n-gramy w połączeniu MNB, aby poprawić skuteczność klasyficji wiadomości e-mail.\n",
    "\n",
    "#### Opis:\n",
    "1. Zbierz zbiór danych zawierający etykiety (spam/nie-spam) oraz treść wiadomości e-mail np. [Enron-Spam](http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/index.html) lub [SMS Spam Collection](https://archive.ics.uci.edu/dataset/228/sms+spam+collection) lub [E-mail Spam](https://www.kaggle.com/datasets/balaka18/email-spam-classification-dataset-csv) lub ...\n",
    "2. Przygotuj dane poprzez tworzenie n-gramów z treści wiadomości e-mail tzn. unigramy, bigramy, trigramy.\n",
    "3. Zaimplementuj MNB, który będzie w stanie klasyfikować wiadomości jako spam lub nie-spam, wykorzystując n-gramy jako cechy.\n",
    "4. Podziel dane na zbiór treningowy i testowy (np. 70% do treningu, 30% do testu).\n",
    "5. Wytrenuj klasyfikator MNB na danych treningowych, wykorzystując n-gramy jako cechy.\n",
    "6. Przetestuj klasyfikator na danych testowych i oceniaj jego skuteczność przy użyciu metryk: [precision i recall](https://en.wikipedia.org/wiki/Precision_and_recall), [f1-score](https://en.wikipedia.org/wiki/F-score) oraz [accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision).\n",
    "7. Dokonaj analizy wyników i porównaj je z wynikami klasyfikatora opartego na słowach.\n",
    "8. Przedstaw wnioski dotyczące skuteczności klasyfikatora opartego na n-gramach oraz wpływu różnych typów n-gramów na skuteczność klasyfikacji.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b2135aa-3e93-4bd9-8d6d-467f14e29f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Classifier:PNBClassifier, ngram_range=(1, 1)\n",
      "Accuracy  | Precision | Recall    | F1_Score \n",
      "0.9809    | 0.9957    | 0.8812    | 0.935    \n",
      "Results for Classifier:PNBClassifier, ngram_range=(2, 2)\n",
      "Accuracy  | Precision | Recall    | F1_Score \n",
      "0.9791    | 0.9871    | 0.8774    | 0.929    \n",
      "Results for Classifier:PNBClassifier, ngram_range=(3, 3)\n",
      "Accuracy  | Precision | Recall    | F1_Score \n",
      "0.9647    | 0.9903    | 0.7816    | 0.8737   \n"
     ]
    }
   ],
   "source": [
    "class PNBClassifier(Classifier):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "    def probability_of_x_condition_c(self, x, c) -> float:\n",
    "        log_p = np.log(self.class_probs[c]) # type: ignore\n",
    "        for token in x.nonzero()[0]:\n",
    "            am_token = self.token_counts_per_class[c][token] \n",
    "            log_p += np.log(am_token) * x[token]\n",
    "            log_p -= np.log(self.total_tokens_per_class[c])\n",
    "        return log_p\n",
    "\n",
    "test(PNBClassifier(), (1,1), X_train, y_train, X_test, y_test)\n",
    "test(PNBClassifier(), (2,2), X_train, y_train, X_test, y_test)\n",
    "test(PNBClassifier(), (3,3), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604fe519",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
